# ğŸš€ SIGAA Extension Scraper: AutomaÃ§Ã£o de InteligÃªncia AcadÃªmica

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![Selenium](https://img.shields.io/badge/Selenium-4.0+-green.svg)](https://www.selenium.dev/)
[![Pandas](https://img.shields.io/badge/Pandas-Latest-informational.svg)](https://pandas.pydata.org/)

## ğŸ“‹ Sobre o Projeto

Este projeto foi desenvolvido para automatizar a coleta e o levantamento de dados dos projetos de extensÃ£o universitÃ¡ria no sistema SIGAA. 

### ğŸ’¡ O Problema
Anteriormente, o levantamento de dados era feito **manualmente** por toda a equipe do setor de extensÃ£o. Milhares de projetos eram divididos entre funcionÃ¡rios que entravam um a um no sistema para extrair informaÃ§Ãµes. Esse processo era:
* **Lento:** Levava dias ou semanas para ser concluÃ­do, comprometendo a mÃ£o de obra dos servidores.
* **SuscetÃ­vel a erros:** A coleta manual aumentava o risco de dados inconsistentes.
* **Custo operacional alto:** Desviava a equipe de tarefas analÃ­ticas para tarefas repetitivas.
 
Lembrando que essa Ã© uma versÃ£o refatorada do projeto, preservando dados sensiveis do sistema da UFPB, apenas para demonstraÃ§Ã£o dos mÃ©todos utilizados na realizaÃ§Ã£o do projeto, podendo ser personalizado para outros sistemas.
### âœ¨ A SoluÃ§Ã£o
Com este scraper, o processo foi transformado em uma **operaÃ§Ã£o de minutos**. O bot realiza o login, navega pelos menus acadÃªmicos e extrai automaticamente dados como:
* TÃ­tulo do Projeto e Edital.
* Nome do Coordenador.
* **Locais de RealizaÃ§Ã£o (Cidades e Estados, bairros, departamentos e etc):** Principal foco para anÃ¡lise de capilaridade e alcance da extensÃ£o.



---

## ğŸ“Š Impacto e Resultados
Os dados estruturados permitem que a gestÃ£o universitÃ¡ria:
1.  **Mapeie o Alcance:** Identificar quantas cidades e estados diferentes sÃ£o atendidos.
2.  **Dashboards de GestÃ£o:** Alimentar relatÃ³rios visuais e Power BI para identificar gargalos.
3.  **IdentificaÃ§Ã£o de Pontos Cegos:** Visualizar Ã¡reas geogrÃ¡ficas com baixa concentraÃ§Ã£o de projetos para expansÃ£o estratÃ©gica.

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Python:** Linguagem base.
* **Selenium WebDriver:** AutomaÃ§Ã£o da navegaÃ§Ã£o e interaÃ§Ã£o com o sistema.
* **Pandas:** EstruturaÃ§Ã£o e limpeza dos dados coletados.
* **Python-dotenv:** Gerenciamento seguro de credenciais e variÃ¡veis de ambiente.

---

## âš™ï¸ ConfiguraÃ§Ã£o e InstalaÃ§Ã£o

### PrÃ©-requisitos
* Python 3.8 ou superior instalado.
* Google Chrome instalado.

### Passo a Passo

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/seu-usuario/Academic-System-Scraper.git](https://github.com/seu-usuario/Academic-System-Scraper.git)
    cd Academic-System-Scraper
    ```

2.  **Instale as dependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```

3.  **Configure as credenciais:**
    * Renomeie o arquivo `.env.example` para `.env`.
    * Insira seu usuÃ¡rio e senha do SIGAA no arquivo `.env`.
    > **Nota:** O arquivo `.env` estÃ¡ no `.gitignore` e nunca serÃ¡ enviado para o repositÃ³rio por questÃµes de seguranÃ§a.

4.  **Execute o script:**
    ```bash
    python academic_scrapper.py
    ```

---

## ğŸ—ï¸ Estrutura do Projeto

* `academic_scrapper.py`: Script principal de automaÃ§Ã£o.
* `.env`: Armazenamento seguro de credenciais (local).
* `.gitignore`: ProteÃ§Ã£o de arquivos sensÃ­veis e temporÃ¡rios.
* `local_survey_2025.xlsx`: Arquivo gerado com os dados consolidados.

---

## ğŸ‘¨â€ğŸ’» Desenvolvedor
* **Hugo Ryan** - https://www.linkedin.com/in/hugo-ryan-9b5621201/
